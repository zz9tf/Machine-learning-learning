{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "def load_data(file_path='data/train.csv', df=None, drop_columns=None, target_column=None):\n",
    "    \"\"\"\n",
    "    Load and preprocess data from a CSV file.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    file_path : str\n",
    "        Path to the CSV file\n",
    "    drop_columns : list\n",
    "        List of columns to drop\n",
    "    target_column : str\n",
    "        Name of the target column\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    X : pandas.DataFrame\n",
    "        Feature matrix\n",
    "    y : pandas.Series\n",
    "        Target variable\n",
    "    \"\"\"\n",
    "    # Load the data\n",
    "    if df is None:\n",
    "        df = pd.read_csv(file_path)\n",
    "    if drop_columns:\n",
    "        # Drop specified columns\n",
    "        df.drop(columns=drop_columns, inplace=True)\n",
    "    if target_column is None:\n",
    "        return df\n",
    "    # Extract target variable\n",
    "    y = df[target_column]\n",
    "    \n",
    "    # Remove target from features\n",
    "    df.drop(columns=[target_column], inplace=True)\n",
    "    \n",
    "    # Set feature matrix\n",
    "    X = df\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "path = './week2 - EDA/data/adult_test.csv'\n",
    "print(os.path.abspath(path))\n",
    "print(os.path.exists(os.path.abspath(path)))\n",
    "# for filename in os.listdir(path):\n",
    "#     print(filename)\n",
    "\n",
    "df = pd.read_csv(path, skiprows=[0,1])\n",
    "df = load_data(df=df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### df visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "df.head()\n",
    "\n",
    "# Basic filtering\n",
    "# df[(df['column1'] == 'value1') | (df['column2'] == 'value2') & (df['column3'] == 'value3')]\n",
    "\n",
    "# select columns by index\n",
    "# columns =  df.columns # get columns\n",
    "# df[['age','hours-per-week']] # by name\n",
    "# df[columns[[1,5,7]]] # by columns\n",
    "# df.iloc[:,3] # a number\n",
    "# df.iloc[:,[3,5,6]] # a list\n",
    "# df.iloc[:,::2] # a range\n",
    "##########################\n",
    "# Join\n",
    "# we are interested in only patients from hospital1\n",
    "# df_left = df1.merge(df2,how='left',on='ID') # IDs from the left dataframe (df1) are kept\n",
    "# print(df_left)\n",
    "\n",
    "# we are interested in only patients from hospital2\n",
    "#df_right = df1.merge(df2,how='right',on='ID') # IDs from the right dataframe (df2) are kept\n",
    "#print(df_right)\n",
    "\n",
    "# we are interested in patiens who were in both hospitals\n",
    "#df_inner = df1.merge(df2,how='inner',on='ID') # merging on IDs present in both dataframes\n",
    "#print(df_inner)\n",
    "\n",
    "# we are interested in all patients who visited at least one of the hospitals\n",
    "#df_outer = df1.merge(df2,how='outer',on='ID')  # merging on IDs present in any dataframe\n",
    "#print(df_outer)\n",
    "############################\n",
    "# Append dataframe\n",
    "# df_append = pd.concat([df1,df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_and_visualize_dataframe(df, figsize=(5, 3), continuous_bins='auto', \n",
    "                                   log_threshold=1000, max_categories=15, \n",
    "                                   plot_all=True, exclude_cols=None):\n",
    "    \"\"\"\n",
    "    Analyze and visualize the statistical distribution of each column in a DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas DataFrame\n",
    "        DataFrame to analyze\n",
    "    figsize : tuple, optional (default=(5, 3))\n",
    "        Figure size for plots\n",
    "    continuous_bins : str or int, optional (default='auto')\n",
    "        Number of bins for continuous variables, 'auto' uses unique values or sqrt rule\n",
    "    log_threshold : int, optional (default=1000)\n",
    "        Threshold for using log scale if max/min ratio exceeds this value\n",
    "    max_categories : int, optional (default=15)\n",
    "        Maximum number of categories to display in bar plots\n",
    "    plot_all : bool, optional (default=True)\n",
    "        Whether to generate plots for all columns\n",
    "    exclude_cols : list, optional (default=None)\n",
    "        List of column names to exclude from analysis\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary with analysis results for each column\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import warnings\n",
    "    \n",
    "    warnings.filterwarnings('ignore', category=UserWarning)\n",
    "    \n",
    "    # Initialize results dictionary\n",
    "    results = {}\n",
    "    exclude_cols = exclude_cols or []\n",
    "    \n",
    "    # Track invisible/problematic data\n",
    "    invisible_data = {}\n",
    "    \n",
    "    # Function to determine if a column should use log scale\n",
    "    def should_use_log_scale(series):\n",
    "        if series.min() <= 0:\n",
    "            return False\n",
    "        if series.max() / max(series.min(), 1e-10) > log_threshold:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    print(f\"All columns and their data types ({len(df.columns)}):\")\n",
    "    print(df.dtypes)\n",
    "    \n",
    "    # Iterate through each column\n",
    "    for col in df.columns:\n",
    "        if col in exclude_cols:\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\n{'='*50}\\nAnalyzing column: {col}\\n{'='*50}\")\n",
    "        \n",
    "        # Store basic information\n",
    "        results[col] = {\n",
    "            'dtype': str(df[col].dtype),\n",
    "            'is_numeric': pd.api.types.is_numeric_dtype(df[col]),\n",
    "            'unique_count': df[col].nunique(),\n",
    "            'missing_count': df[col].isna().sum(),\n",
    "            'missing_percentage': (df[col].isna().sum() / len(df)) * 100\n",
    "        }\n",
    "        \n",
    "        # Print basic statistics\n",
    "        print(f\"Data type: {results[col]['dtype']}\")\n",
    "        print(f\"Unique values: {results[col]['unique_count']}\")\n",
    "        print(f\"Missing values: {results[col]['missing_count']} ({results[col]['missing_percentage']:.2f}%)\")\n",
    "        \n",
    "        # Track invisible data\n",
    "        if results[col]['missing_count'] > 0:\n",
    "            invisible_data[col] = {'missing': results[col]['missing_count']}\n",
    "            \n",
    "        # For numeric columns\n",
    "        if results[col]['is_numeric']:\n",
    "            # Calculate descriptive statistics\n",
    "            desc = df[col].describe()\n",
    "            results[col]['stats'] = desc.to_dict()\n",
    "            print(\"\\nDescriptive statistics:\")\n",
    "            print(desc)\n",
    "            \n",
    "            # Detect zeros and infinities\n",
    "            zero_count = (df[col] == 0).sum()\n",
    "            inf_count = np.isinf(df[col]).sum() if np.issubdtype(df[col].dtype, np.number) else 0\n",
    "            \n",
    "            if zero_count > 0:\n",
    "                print(f\"Zero values: {zero_count} ({zero_count/len(df)*100:.2f}%)\")\n",
    "                invisible_data.setdefault(col, {})['zeros'] = zero_count\n",
    "                \n",
    "            if inf_count > 0:\n",
    "                print(f\"Infinite values: {inf_count} ({inf_count/len(df)*100:.2f}%)\")\n",
    "                invisible_data.setdefault(col, {})['infinities'] = inf_count\n",
    "            \n",
    "            # Detect if it should use log scale\n",
    "            use_log = should_use_log_scale(df[col].dropna()) if log_threshold else False\n",
    "            if use_log:\n",
    "                print(\"Distribution is highly skewed, log scale recommended\")\n",
    "                results[col]['log_recommended'] = True\n",
    "            else:\n",
    "                results[col]['log_recommended'] = False\n",
    "                \n",
    "            # Plot histogram if requested\n",
    "            if plot_all:\n",
    "                plt.figure(figsize=figsize)\n",
    "                \n",
    "                # Determine bin count\n",
    "                if continuous_bins == 'auto':\n",
    "                    if results[col]['unique_count'] < 50:\n",
    "                        bins = results[col]['unique_count']\n",
    "                    else:\n",
    "                        bins = int(np.sqrt(df.shape[0]))  # Square root rule\n",
    "                else:\n",
    "                    bins = continuous_bins\n",
    "                \n",
    "                # Use log scale if appropriate\n",
    "                if use_log and df[col].min() > 0:\n",
    "                    non_zero = df[col][df[col] > 0]\n",
    "                    log_bins = np.logspace(\n",
    "                        np.log10(max(non_zero.min(), 1e-10)),\n",
    "                        np.log10(non_zero.max()),\n",
    "                        bins\n",
    "                    )\n",
    "                    non_zero.plot.hist(bins=log_bins, log=True)\n",
    "                    plt.semilogx()\n",
    "                    print(\"Using log scale for visualization\")\n",
    "                else:\n",
    "                    df[col].plot.hist(bins=bins)\n",
    "                    \n",
    "                plt.xlabel(col)\n",
    "                plt.ylabel('count')\n",
    "                plt.title(f'Distribution of {col}')\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "                \n",
    "        # For categorical columns\n",
    "        else:\n",
    "            # Get value counts\n",
    "            value_counts = df[col].value_counts()\n",
    "            top_n = min(max_categories, len(value_counts))\n",
    "            \n",
    "            print(f\"\\nTop {top_n} values:\")\n",
    "            print(value_counts.head(top_n))\n",
    "            \n",
    "            if len(value_counts) > max_categories:\n",
    "                print(f\"... and {len(value_counts) - max_categories} more categories\")\n",
    "                \n",
    "            results[col]['top_values'] = value_counts.head(top_n).to_dict()\n",
    "            \n",
    "            # Plot bar chart if requested\n",
    "            if plot_all:\n",
    "                plt.figure(figsize=figsize)\n",
    "                \n",
    "                if len(value_counts) > max_categories:\n",
    "                    # For too many categories, show top N and group others\n",
    "                    top_values = value_counts.head(max_categories-1)\n",
    "                    others_sum = value_counts.iloc[max_categories-1:].sum()\n",
    "                    \n",
    "                    combined = pd.concat([\n",
    "                        top_values, \n",
    "                        pd.Series({'Others': others_sum})\n",
    "                    ])\n",
    "                    \n",
    "                    combined.plot.barh()\n",
    "                    print(f\"Grouped {len(value_counts) - (max_categories-1)} categories as 'Others'\")\n",
    "                else:\n",
    "                    value_counts.plot.barh()\n",
    "                    \n",
    "                plt.ylabel(col)\n",
    "                plt.xlabel('count')\n",
    "                plt.title(f'Distribution of {col}')\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "    \n",
    "    # Print summary of invisible data\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"SUMMARY OF NON-VISIBLE DATA:\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    if invisible_data:\n",
    "        for col, issues in invisible_data.items():\n",
    "            print(f\"\\n{col}:\")\n",
    "            for issue_type, count in issues.items():\n",
    "                print(f\"  - {issue_type}: {count} ({count/len(df)*100:.2f}%)\")\n",
    "    else:\n",
    "        print(\"No non-visible data detected\")\n",
    "            \n",
    "    return results\n",
    "\n",
    "# Basic usage\n",
    "results = analyze_and_visualize_dataframe(df)\n",
    "\n",
    "# Custom usage\n",
    "results = analyze_and_visualize_dataframe(\n",
    "    df,\n",
    "    figsize=(8, 4),\n",
    "    continuous_bins=30,\n",
    "    log_threshold=100,\n",
    "    max_categories=10,\n",
    "    exclude_cols=['id', 'customer_id']  # Skip these columns\n",
    ")\n",
    "\n",
    "# Just analyze without plotting\n",
    "analysis = analyze_and_visualize_dataframe(df, plot_all=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plot\n",
    "\n",
    "| *Visualization types*        \t|    column continuous    \t| column categorical \t|\n",
    "|---------------------\t|:----------------------:\t|:-----------------:\t|\n",
    "| __column continuous__    \t| scatter plot, heatmap \t| category-specific histograms, box plot, violin plot |\n",
    "| __column categorical__   \t| category-specific histograms, box plot, violin plot |  stacked bar plot  \t|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### scatter plot- points position distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,3))\n",
    "df.plot.scatter('age','hours-per-week',s=10,alpha=0.1) # alpha=0.1,s=10\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### heatmap - number of points distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2d_histogram(df, x_col, y_col, nbins=40, figsize=(5, 3), log_scale=True, \n",
    "                      min_count=0.1, tick_freq=4, cmap=None, title=None):\n",
    "    \"\"\"\n",
    "    Create a 2D histogram heatmap from two DataFrame columns.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas DataFrame\n",
    "        DataFrame containing the data\n",
    "    x_col : str\n",
    "        Column name for x-axis\n",
    "    y_col : str\n",
    "        Column name for y-axis\n",
    "    nbins : int, optional (default=40)\n",
    "        Number of bins for both axes\n",
    "    figsize : tuple, optional (default=(5, 3))\n",
    "        Figure size (width, height) in inches\n",
    "    log_scale : bool, optional (default=True)\n",
    "        Whether to apply log10 to the counts\n",
    "    min_count : float, optional (default=0.1)\n",
    "        Minimum value to replace zeros with (for log scaling)\n",
    "    tick_freq : int, optional (default=4)\n",
    "        Frequency of tick marks on both axes\n",
    "    cmap : str or colormap, optional (default=None)\n",
    "        Matplotlib colormap to use\n",
    "    title : str, optional (default=None)\n",
    "        Title for the plot\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    matplotlib.figure.Figure\n",
    "        The figure object containing the plot\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # Create 2D histogram\n",
    "    heatmap, xedges, yedges = np.histogram2d(df[x_col], df[y_col], bins=nbins)\n",
    "    extent = [xedges[0], xedges[-1], yedges[0], yedges[-1]]\n",
    "    \n",
    "    # Replace zeros to avoid log(0) if using log scale\n",
    "    if log_scale:\n",
    "        heatmap[heatmap == 0] = min_count\n",
    "    \n",
    "    # Create figure\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    \n",
    "    # Plot heatmap\n",
    "    if log_scale:\n",
    "        plt.imshow(np.log10(heatmap).T, origin='lower', vmin=0, extent=extent, cmap=cmap)\n",
    "        cbar_label = 'log10(count)'\n",
    "    else:\n",
    "        plt.imshow(heatmap.T, origin='lower', extent=extent, cmap=cmap)\n",
    "        cbar_label = 'count'\n",
    "    \n",
    "    # Add labels and ticks\n",
    "    plt.xlabel(x_col)\n",
    "    plt.ylabel(y_col)\n",
    "    \n",
    "    # Add ticks at specified frequency\n",
    "    x_ticks = np.linspace(xedges[0], xedges[-1], nbins+1)[::tick_freq]\n",
    "    y_ticks = np.linspace(yedges[0], yedges[-1], nbins+1)[::tick_freq]\n",
    "    plt.xticks(x_ticks, x_ticks.astype(int))\n",
    "    plt.yticks(y_ticks, y_ticks.astype(int))\n",
    "    \n",
    "    # Add colorbar and title\n",
    "    plt.colorbar(label=cbar_label)\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Basic usage\n",
    "fig = plot_2d_histogram(df, 'age', 'hours-per-week')\n",
    "plt.show()\n",
    "\n",
    "# Customized usage\n",
    "fig = plot_2d_histogram(\n",
    "    df, \n",
    "    'age', \n",
    "    'hours-per-week', \n",
    "    nbins=50, \n",
    "    figsize=(8, 5), \n",
    "    log_scale=True, \n",
    "    cmap='viridis', \n",
    "    title='Age vs Hours per Week Distribution'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### stacked bar plot - percentage distribution of categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stacked_categorical_distribution(df, x_col, y_col, figsize=(5, 3), legend_loc=4, \n",
    "                                          title=None, normalize=True, rotation=0):\n",
    "    \"\"\"\n",
    "    Create a stacked bar chart showing the distribution of two categorical variables.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas DataFrame\n",
    "        DataFrame containing the data\n",
    "    x_col : str\n",
    "        Column name for x-axis (categories to compare)\n",
    "    y_col : str\n",
    "        Column name for values to stack within each x category\n",
    "    figsize : tuple, optional (default=(5, 3))\n",
    "        Figure size (width, height) in inches\n",
    "    legend_loc : int or str, optional (default=4)\n",
    "        Location of the legend (1-10 or 'best', 'upper right', etc.)\n",
    "    title : str, optional (default=None)\n",
    "        Title for the plot\n",
    "    normalize : bool, optional (default=True)\n",
    "        Whether to normalize rows to show proportions instead of counts\n",
    "    rotation : int, optional (default=0)\n",
    "        Rotation angle for x-tick labels\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    matplotlib.figure.Figure\n",
    "        The figure object containing the plot\n",
    "    pandas.DataFrame\n",
    "        The count or normalized matrix used for plotting\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # Count occurrences of each combination\n",
    "    count_matrix = df.groupby([x_col, y_col]).size().unstack(fill_value=0)\n",
    "    \n",
    "    if normalize:\n",
    "        # Normalize rows to show proportions\n",
    "        matrix_for_plot = count_matrix.div(count_matrix.sum(axis=1), axis=0)\n",
    "        ylabel = f'Fraction of {x_col} in each group'\n",
    "    else:\n",
    "        # Use raw counts\n",
    "        matrix_for_plot = count_matrix\n",
    "        ylabel = 'Count'\n",
    "    \n",
    "    # Create the plot\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    matrix_for_plot.plot(kind='bar', stacked=True)\n",
    "    \n",
    "    # Add labels and customize\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel(x_col)\n",
    "    plt.legend(loc=legend_loc, title=y_col)\n",
    "    \n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    \n",
    "    # Set rotation for x-tick labels\n",
    "    plt.xticks(rotation=rotation)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig, matrix_for_plot\n",
    "\n",
    "# Basic usage with default settings\n",
    "fig, matrix = plot_stacked_categorical_distribution(df, 'race', 'gross-income')\n",
    "plt.show()\n",
    "\n",
    "# Customized usage\n",
    "fig, matrix = plot_stacked_categorical_distribution(\n",
    "    df, \n",
    "    'race', \n",
    "    'gross-income', \n",
    "    figsize=(10, 6),\n",
    "    legend_loc='lower right',\n",
    "    title='Income Distribution by Race',\n",
    "    normalize=True,\n",
    "    rotation=45\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "# Access the matrix data\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### category-specific histograms - continuous distribution split by categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histograms_by_category(df, value_col, category_col, figsize=(8, 5), bins=20, \n",
    "                               alpha=0.5, density=True, range_tuple=None, \n",
    "                               title=None, colors=None, grid=True):\n",
    "    \"\"\"\n",
    "    Plot overlapping histograms of a value column for each category in a categorical column.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas DataFrame\n",
    "        DataFrame containing the data\n",
    "    value_col : str\n",
    "        Column name for the continuous variable to histogram (x-axis)\n",
    "    category_col : str\n",
    "        Column name for the categorical variable that defines groups\n",
    "    figsize : tuple, optional (default=(8, 5))\n",
    "        Figure size (width, height) in inches\n",
    "    bins : int, optional (default=20)\n",
    "        Number of bins for the histogram\n",
    "    alpha : float, optional (default=0.5)\n",
    "        Transparency level for the histogram bars\n",
    "    density : bool, optional (default=True)\n",
    "        Whether to normalize the histogram to show density instead of counts\n",
    "    range_tuple : tuple, optional (default=None)\n",
    "        Range of values to include in the histogram (min, max)\n",
    "        If None, the range is determined from the data\n",
    "    title : str, optional (default=None)\n",
    "        Title for the plot\n",
    "    colors : list or dict, optional (default=None)\n",
    "        List of colors for each category or dictionary mapping categories to colors\n",
    "    grid : bool, optional (default=True)\n",
    "        Whether to show grid lines\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    matplotlib.figure.Figure\n",
    "        The figure object containing the plot\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    \n",
    "    # Get unique categories\n",
    "    categories = df[category_col].unique()\n",
    "    \n",
    "    # Determine range if not provided\n",
    "    if range_tuple is None:\n",
    "        range_tuple = (df[value_col].min(), df[value_col].max())\n",
    "    \n",
    "    # Create figure\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    \n",
    "    # Create color mapping if colors provided as list\n",
    "    if colors is not None and not isinstance(colors, dict):\n",
    "        colors = {cat: color for cat, color in zip(categories, colors)}\n",
    "    \n",
    "    # Plot histograms for each category\n",
    "    for i, category in enumerate(categories):\n",
    "        # Get data for this category\n",
    "        data = df[df[category_col] == category][value_col]\n",
    "        \n",
    "        # Skip if no data\n",
    "        if len(data) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Get color for this category\n",
    "        if colors is not None and isinstance(colors, dict):\n",
    "            color = colors.get(category)\n",
    "            plt.hist(data, alpha=alpha, label=category, range=range_tuple, \n",
    "                    bins=bins, density=density, color=color)\n",
    "        else:\n",
    "            plt.hist(data, alpha=alpha, label=category, range=range_tuple, \n",
    "                    bins=bins, density=density)\n",
    "    \n",
    "    # Add labels and customize\n",
    "    plt.xlabel(value_col)\n",
    "    plt.ylabel('Density' if density else 'Count')\n",
    "    plt.legend(title=category_col)\n",
    "    \n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    \n",
    "    if grid:\n",
    "        plt.grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Basic usage with default settings\n",
    "fig = plot_histograms_by_category(df, 'age', 'gross-income')\n",
    "plt.show()\n",
    "\n",
    "# Customized usage\n",
    "fig = plot_histograms_by_category(\n",
    "    df, \n",
    "    'age', \n",
    "    'gross-income', \n",
    "    figsize=(10, 6),\n",
    "    bins=30,\n",
    "    alpha=0.7,\n",
    "    density=True,\n",
    "    title='Age Distribution by Income Level',\n",
    "    colors={'<=50K': 'blue', '>50K': 'red'}\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### box plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['age','gross-income']].boxplot(by='gross-income')\n",
    "plt.ylabel('age')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### violin plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [df[df['gross-income']==' <=50K']['age'].values,\n",
    "           df[df['gross-income']==' >50K']['age'].values]\n",
    "\n",
    "plt.violinplot(dataset = dataset)\n",
    "plt.xticks([1,2],['<=50k','>50k'])\n",
    "plt.ylabel('age')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### correlation & autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Union, Optional\n",
    "import seaborn as sns\n",
    "\n",
    "def correlation(x: pd.Series, y: pd.Series, method: str = 'pearson') -> float:\n",
    "    \"\"\"\n",
    "    Compute correlation between two series with automatic alignment\n",
    "    \n",
    "    Args:\n",
    "        x: First input series\n",
    "        y: Second input series\n",
    "        method: Correlation method ('pearson', 'spearman', 'kendall')\n",
    "        \n",
    "    Returns:\n",
    "        Correlation coefficient\n",
    "    \"\"\"\n",
    "    # Align and drop NA pairs\n",
    "    aligned = pd.concat([x, y], axis=1).dropna()\n",
    "    if len(aligned) < 2:\n",
    "        return np.nan\n",
    "    return aligned.iloc[:, 0].corr(aligned.iloc[:, 1], method=method)\n",
    "\n",
    "def feature_target_correlation(\n",
    "    X: Union[pd.DataFrame, np.ndarray],\n",
    "    y: Union[pd.Series, np.ndarray],\n",
    "    method: str = 'pearson',\n",
    "    top_n: Optional[int] = None,\n",
    "    visualize: bool = True,\n",
    "    figsize: tuple = (10, 6)\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute correlation between all features and target variable.\n",
    "    \n",
    "    Args:\n",
    "        X: Feature matrix (DataFrame or array)\n",
    "        y: Target variable (Series or array)\n",
    "        method: Correlation method ('pearson', 'spearman', 'kendall')\n",
    "        top_n: Show only top N most correlated features (None for all)\n",
    "        visualize: Whether to create a bar plot\n",
    "        figsize: Figure size when visualizing\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with correlations and p-values (sorted by absolute correlation)\n",
    "    \"\"\"\n",
    "    # Convert inputs to pandas if they aren't already\n",
    "    if not isinstance(X, pd.DataFrame):\n",
    "        X = pd.DataFrame(X)\n",
    "    if not isinstance(y, pd.Series):\n",
    "        y = pd.Series(y)\n",
    "    \n",
    "    # Calculate correlations\n",
    "    corr_results = []\n",
    "    for col in X.columns:\n",
    "        # Drop NA pairs for each feature-target combination\n",
    "        valid = pd.concat([X[col], y], axis=1).dropna()\n",
    "        if len(valid) < 2:\n",
    "            corr = np.nan\n",
    "            pval = np.nan\n",
    "        else:\n",
    "            corr = valid.iloc[:, 0].corr(valid.iloc[:, 1], method=method)\n",
    "            # Calculate p-value for pearson correlation\n",
    "            if method == 'pearson':\n",
    "                from scipy.stats import pearsonr\n",
    "                _, pval = pearsonr(valid.iloc[:, 0], valid.iloc[:, 1])\n",
    "            else:\n",
    "                pval = np.nan\n",
    "        \n",
    "        corr_results.append({\n",
    "            'feature': col,\n",
    "            'correlation': corr,\n",
    "            'abs_correlation': abs(corr),\n",
    "            'p_value': pval\n",
    "        })\n",
    "    \n",
    "    # Create results dataframe\n",
    "    results = pd.DataFrame(corr_results).sort_values('abs_correlation', ascending=False)\n",
    "    \n",
    "    # Filter top N if requested\n",
    "    if top_n is not None:\n",
    "        results = results.head(top_n)\n",
    "    \n",
    "    # Visualization\n",
    "    if visualize:\n",
    "        plt.figure(figsize=figsize)\n",
    "        sns.barplot(\n",
    "            data=results,\n",
    "            x='correlation',\n",
    "            y='feature',\n",
    "            palette='coolwarm',\n",
    "            orient='h'\n",
    "        )\n",
    "        plt.axvline(0, color='black', linestyle='--')\n",
    "        plt.title(f'Feature-Target Correlations ({method.title()} Method)')\n",
    "        plt.xlabel('Correlation Coefficient')\n",
    "        plt.ylabel('Features')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    return results.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Create test data\n",
    "    np.random.seed(42)\n",
    "    dates = pd.date_range('2020-01-01', periods=365*3)\n",
    "    temp = 20 + 10 * np.sin(2 * np.pi * np.arange(len(dates)) / 365) + np.random.normal(0, 2, len(dates))\n",
    "    df = pd.DataFrame({'Date': dates, 'Temp': temp}).set_index('Date')\n",
    "\n",
    "    # Test correlation method\n",
    "    print(\"Correlation between Temp and lagged Temp:\")\n",
    "    print(correlation(df['Temp'], df['Temp'].shift(1)))\n",
    "\n",
    "    # Compare with pandas built-in\n",
    "    pd.plotting.autocorrelation_plot(df['Temp'])\n",
    "    plt.title(\"Pandas Built-in Autocorrelation\")\n",
    "    plt.show()\n",
    "    \n",
    "    data = pd.DataFrame({\n",
    "        'age': np.random.randint(20, 70, 100),\n",
    "        'income': np.random.normal(50000, 15000, 100),\n",
    "        'education': np.random.choice(['High School', 'College', 'Grad'], 100),\n",
    "        'credit_score': np.random.randint(300, 850, 100),\n",
    "        'target': np.random.normal(0, 1, 100) + 0.5 * np.random.randint(20, 70, 100)/100\n",
    "    })\n",
    "\n",
    "    # One-hot encode categorical variables\n",
    "    data = pd.get_dummies(data, columns=['education'])\n",
    "    results = feature_target_correlation(\n",
    "        X=data.drop('target', axis=1),\n",
    "        y=data['target'],\n",
    "        method='pearson',\n",
    "        visualize=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### f_regression & mutual_info_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_feature_importance(X, y, problem_type='regression', k_best=None, percentile=None, visualize=True, random_state=10):\n",
    "    \"\"\"\n",
    "    Analyze feature importance using F-test and mutual information, and select top features.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : pandas DataFrame or numpy.ndarray\n",
    "        Feature matrix\n",
    "    y : pandas Series or numpy.ndarray\n",
    "        Target variable\n",
    "    problem_type : str, optional (default='regression')\n",
    "        Type of problem: 'regression' or 'classification'\n",
    "    k_best : int, optional (default=None)\n",
    "        Number of top features to select using SelectKBest\n",
    "    percentile : int, optional (default=None)\n",
    "        Percentile of top features to select using SelectPercentile\n",
    "    visualize : bool, optional (default=True)\n",
    "        Whether to visualize feature relationships\n",
    "    random_state : int, optional (default=10)\n",
    "        Random seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary containing f_test, p_values, mutual_information, selected_features_k_best,\n",
    "        selected_features_percentile, and the transformed X data\n",
    "        \n",
    "        f_test: Linear relationships between features and target (The larger the better)\n",
    "        p_values: array of p-values(The smaller the better, <0.5 means significant)\n",
    "        mutual_information: Any statistical dependency (linear or non-linear) (The larger the better)\n",
    "        selected_features_k_best: array of boolean values indicating selected features\n",
    "        selected_features_percentile: array of boolean values indicating selected features\n",
    "        X_k_best: array of selected features\n",
    "        X_percentile: array of selected features\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import pandas as pd\n",
    "    from sklearn.feature_selection import (\n",
    "        f_regression, mutual_info_regression, \n",
    "        f_classif, mutual_info_classif,\n",
    "        SelectKBest, SelectPercentile\n",
    "    )\n",
    "    \n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    # Handle pandas DataFrame/Series if provided\n",
    "    X_is_pandas = isinstance(X, pd.DataFrame)\n",
    "    feature_names = X.columns if X_is_pandas else None\n",
    "    \n",
    "    # Convert to numpy arrays for computation if needed\n",
    "    X_np = X.values if X_is_pandas else X\n",
    "    y_np = y.values if isinstance(y, pd.Series) else y\n",
    "    \n",
    "    # Select appropriate scoring functions based on problem type\n",
    "    if problem_type == 'regression':\n",
    "        f_test_func = f_regression\n",
    "        mi_func = mutual_info_regression\n",
    "    elif problem_type == 'classification':\n",
    "        f_test_func = f_classif\n",
    "        mi_func = mutual_info_classif\n",
    "    else:\n",
    "        raise ValueError(\"problem_type must be 'regression' or 'classification'\")\n",
    "    \n",
    "    # Calculate feature importance metrics\n",
    "    f_test, p_values = f_test_func(X_np, y_np)\n",
    "    mi = mi_func(X_np, y_np)\n",
    "    \n",
    "    # Print feature importance metrics with feature names if available\n",
    "    if X_is_pandas:\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'Feature': feature_names,\n",
    "            'F-Score': f_test,\n",
    "            'P-Value': p_values,\n",
    "            'Mutual Info': mi\n",
    "        })\n",
    "        print(feature_importance)\n",
    "    else:\n",
    "        print('f score', f_test)\n",
    "        print('p values', p_values)\n",
    "        print('mi', mi)\n",
    "    \n",
    "    # Visualization\n",
    "    if visualize:\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        for i in range(min(3, X_np.shape[1])):  # Show at most 3 features\n",
    "            plt.subplot(1, min(3, X_np.shape[1]), i + 1)\n",
    "            plt.scatter(X_np[:, i], y_np, edgecolor='black', s=20)\n",
    "            \n",
    "            # Use feature names if available\n",
    "            if X_is_pandas:\n",
    "                plt.xlabel(f\"{feature_names[i]}\", fontsize=14)\n",
    "            else:\n",
    "                plt.xlabel(f\"$x_{{{i + 1}}}$\", fontsize=14)\n",
    "                \n",
    "            if i == 0:\n",
    "                plt.ylabel(\"$y$\", fontsize=14)\n",
    "            plt.title(f\"F-test={f_test[i]:.2f}, MI={mi[i]:.2f}\", fontsize=16)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Initialize return values\n",
    "    result = {\n",
    "        'f_test': f_test,\n",
    "        'p_values': p_values,\n",
    "        'mutual_information': mi,\n",
    "        'selected_features_k_best': None,\n",
    "        'selected_features_percentile': None,\n",
    "        'X_k_best': None,\n",
    "        'X_percentile': None\n",
    "    }\n",
    "    \n",
    "    if k_best:\n",
    "        # Select k best features\n",
    "        f_select = SelectKBest(mi_func, k=k_best)\n",
    "        X_k_best = f_select.fit_transform(X_np, y_np)\n",
    "        selected_features_k_best = f_select.get_support()\n",
    "        \n",
    "        if visualize and k_best == 1:  # Only show if k=1\n",
    "            plt.figure(figsize=(6, 4))\n",
    "            plt.scatter(X_k_best, y_np, edgecolor='k')\n",
    "            plt.xlabel('Selected Feature')\n",
    "            plt.ylabel('Target')\n",
    "            plt.title('Relationship with Selected Feature')\n",
    "            plt.show()\n",
    "        \n",
    "        # Return a DataFrame if input was DataFrame\n",
    "        if X_is_pandas:\n",
    "            selected_feature_names = feature_names[selected_features_k_best]\n",
    "            print(\"Selected features (k_best):\", selected_feature_names.tolist())\n",
    "            X_k_best = pd.DataFrame(X_k_best, columns=selected_feature_names, index=X.index)\n",
    "        else:\n",
    "            print(\"Selected features (k_best):\", selected_features_k_best)\n",
    "        \n",
    "        result['selected_features_k_best'] = selected_features_k_best\n",
    "        result['X_k_best'] = X_k_best\n",
    "    \n",
    "    if percentile:  \n",
    "        # Select features by percentile\n",
    "        f_selector = SelectPercentile(mi_func, percentile=percentile)\n",
    "        X_percentile = f_selector.fit_transform(X_np, y_np)\n",
    "        selected_features_percentile = f_selector.get_support()\n",
    "        \n",
    "        # Return a DataFrame if input was DataFrame\n",
    "        if X_is_pandas:\n",
    "            selected_feature_names = feature_names[selected_features_percentile]\n",
    "            print(\"Selected features (percentile):\", selected_feature_names.tolist())\n",
    "            X_percentile = pd.DataFrame(X_percentile, columns=selected_feature_names, index=X.index)\n",
    "        else:\n",
    "            print(\"Selected features (percentile):\", selected_features_percentile)\n",
    "            \n",
    "        result['selected_features_percentile'] = selected_features_percentile\n",
    "        result['X_percentile'] = X_percentile\n",
    "    \n",
    "    return result\n",
    "    \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Generate sample data\n",
    "np.random.seed(10)\n",
    "X_np = np.random.rand(1000, 3)\n",
    "y_np = X_np[:, 0] + np.sin(6 * np.pi * X_np[:, 1]) + 0.1 * X_np[:, 2]\n",
    "\n",
    "# Convert to pandas DataFrame/Series\n",
    "X = pd.DataFrame(X_np, columns=['feature_1', 'feature_2', 'feature_3'])\n",
    "y = pd.Series(y_np, name='target')\n",
    "\n",
    "# Analyze feature importance\n",
    "results = analyze_feature_importance(X, y, k_best=2, percentile=66)\n",
    "\n",
    "# Access results\n",
    "if results['selected_features_k_best'] is not None:\n",
    "    print(\"\\nTop 2 features:\", X.columns[results['selected_features_k_best']].tolist())\n",
    "if results['selected_features_percentile'] is not None:\n",
    "    print(\"Features in top 66 percentile:\", X.columns[results['selected_features_percentile']].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "# create a test set without considering groups\n",
    "X_other, X_test, y_other, y_test = train_test_split(X, y, test_size=0.2, random_state=0,stratify=y)\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "# create a test set based on groups\n",
    "groups = df['patient ID'] # a categorical column\n",
    "splitter = GroupShuffleSplit(n_splits=1, train_size=.8, random_state=0)\n",
    "for i_other,i_test in splitter.split(X, y, groups):\n",
    "    X_other, y_other, groups_other = X.iloc[i_other], y.iloc[i_other], groups.iloc[i_other]\n",
    "    X_test, y_test, groups_test = X.iloc[i_test], y.iloc[i_test], groups.iloc[i_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cv search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "kf = GroupKFold(n_splits=10)\n",
    "# create the pipeline: preprocessor + supervised ML method\n",
    "scaler = StandardScaler()\n",
    "pipe = make_pipeline(scaler,SVC())\n",
    "# the parameter(s) we want to tune\n",
    "param_grid = {'svc__C': np.logspace(-3,4,num=8),'svc__gamma': np.logspace(-3,4,num=8)}\n",
    "# prepare gridsearch\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid,scoring = make_scorer(accuracy_score),\n",
    "                    cv=kf, return_train_score = True)\n",
    "# do kfold CV on _other\n",
    "grid.fit(X_other, y_other, groups=groups_other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. handle missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_missing_value(df, plot=True):\n",
    "    print('data dimensions:',df.shape)\n",
    "    perc_missing_per_ftr = df.isnull().sum(axis=0)/df.shape[0]\n",
    "    print('fraction of missing values in features:')\n",
    "    print(perc_missing_per_ftr[perc_missing_per_ftr > 0])\n",
    "    print('data types of the features with missing values:')\n",
    "    print(df[perc_missing_per_ftr[perc_missing_per_ftr > 0].index].dtypes)\n",
    "    frac_missing = sum(df.isnull().sum(axis=1)!=0)/df.shape[0]\n",
    "    print('fraction of points with missing values:',frac_missing)\n",
    "\n",
    "    if plot:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plot_df = perc_missing_per_ftr[perc_missing_per_ftr > 0].sort_values(ascending=False)\n",
    "        plot_df.plot(kind='bar', color='steelblue')\n",
    "\n",
    "        plt.xlabel('feature')\n",
    "        plt.ylabel('fraction of missing values')\n",
    "        plt.title('Fraction of missing value of each feature')\n",
    "\n",
    "        plt.ylim(0, max(perc_missing_per_ftr) * 1.15)\n",
    "\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "visualize_missing_value(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop missing value by row/columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "# by default, rows/points are dropped\n",
    "df_r = df.dropna()\n",
    "print(df_r.shape)\n",
    "# drop features with missing values\n",
    "df_c = df.dropna(axis=1)\n",
    "print(df_c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fillna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna('missing')\n",
    "\n",
    "df['A'] = df['A'].fillna(0)\n",
    "df['C'] = df['C'].fillna(df['C'].mean())\n",
    "\n",
    "df.fillna({'A': -1, 'B': 'empty'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### onehot_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_encoded = pd.get_dummies(df, columns=['column1', 'column2']) # , drop_first=True\n",
    "\n",
    "# Align test data with same columns\n",
    "test_df = df\n",
    "test_encoded = pd.get_dummies(test_df, columns=['color'])\n",
    "test_encoded = test_encoded.reindex(columns=train_encoded.columns, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ordinal_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordinal_encode_categories(df, columns, category_orders=None, suffix='_encoded', \n",
    "                             inplace=False, return_encoder=False):\n",
    "    \"\"\"\n",
    "    Encode categorical columns using OrdinalEncoder with specified or inferred category orders.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas DataFrame\n",
    "        DataFrame containing the categorical columns to encode\n",
    "    columns : list\n",
    "        List of column names to encode\n",
    "    category_orders : dict or None, optional (default=None)\n",
    "        Dictionary mapping column names to their desired category orders\n",
    "        Example: {'size': ['small', 'medium', 'large']}\n",
    "        If None, categories will be determined from the data\n",
    "    suffix : str, optional (default='_encoded')\n",
    "        Suffix to add to column names for the encoded versions\n",
    "    inplace : bool, optional (default=False)\n",
    "        Whether to modify the original DataFrame or create a copy\n",
    "    return_encoder : bool, optional (default=False)\n",
    "        Whether to return the fitted encoder object\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame with added encoded columns\n",
    "    sklearn.preprocessing.OrdinalEncoder (optional)\n",
    "        The fitted encoder object, returned only if return_encoder=True\n",
    "    \"\"\"\n",
    "    from sklearn.preprocessing import OrdinalEncoder\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Make a copy if not inplace\n",
    "    if not inplace:\n",
    "        df = df.copy()\n",
    "    \n",
    "    # Prepare categories\n",
    "    if category_orders is None:\n",
    "        # If no orders provided, let the encoder determine categories from the data\n",
    "        encoder = OrdinalEncoder()\n",
    "    else:\n",
    "        # Use provided category orders\n",
    "        categories = [category_orders.get(col, None) for col in columns]\n",
    "        # For any None values, determine from data\n",
    "        for i, cats in enumerate(categories):\n",
    "            if cats is None:\n",
    "                # Replace None with unique values from the column\n",
    "                categories[i] = sorted(df[columns[i]].unique())\n",
    "        encoder = OrdinalEncoder(categories=categories)\n",
    "    \n",
    "    # Fit and transform the data\n",
    "    encoded_data = encoder.fit_transform(df[columns])\n",
    "    \n",
    "    # Create column names for encoded data\n",
    "    encoded_columns = [f\"{col}{suffix}\" for col in columns]\n",
    "    \n",
    "    # Convert to DataFrame and add to original\n",
    "    df_encoded = pd.DataFrame(encoded_data, columns=encoded_columns, index=df.index)\n",
    "    \n",
    "    # Add encoded columns to the original DataFrame\n",
    "    for col in encoded_columns:\n",
    "        df[col] = df_encoded[col]\n",
    "    \n",
    "    # Return results\n",
    "    if return_encoder:\n",
    "        return df, encoder\n",
    "    else:\n",
    "        return df\n",
    "\n",
    "# Apply ordinal encoding\n",
    "df_encoded = ordinal_encode_categories(df, ['education', 'workclass'])\n",
    "print(df_encoded.columns)\n",
    "print(df_encoded[['education_encoded', 'workclass_encoded']])\n",
    "\n",
    "# If you need the encoder for later use:\n",
    "df_encoded, encoder = ordinal_encode_categories(df, ['education', 'workclass'], return_encoder=True)\n",
    "\n",
    "# To transform new data with the same encoder:\n",
    "# new_encoded_data = encoder.transform(new_df[['size', 'priority']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### standard scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_numerical_df(df, mean=None, std=None):\n",
    "    \"\"\"\n",
    "    Standardize numerical features in a DataFrame (z-score normalization)\n",
    "    Args:\n",
    "        df: Input pandas DataFrame\n",
    "        mean: Precomputed mean Series (if None, computes from df)\n",
    "        std: Precomputed std Series (if None, computes from df)\n",
    "    Returns:\n",
    "        Scaled DataFrame and computed (mean, std)\n",
    "    \"\"\"\n",
    "    numerical_cols = df.select_dtypes(include=['number']).columns\n",
    "    \n",
    "    if mean is None or std is None:\n",
    "        # Compute mean and std while ignoring NaN values\n",
    "        mean = df[numerical_cols].mean(skipna=True)\n",
    "        std = df[numerical_cols].std(skipna=True)\n",
    "        std[std == 0] = 1.0  # avoid division by zero\n",
    "    \n",
    "    # Create copy to avoid SettingWithCopyWarning\n",
    "    df_scaled = df.copy()\n",
    "    \n",
    "    # Fill NaN with mean and apply scaling\n",
    "    for col in numerical_cols:\n",
    "        df_scaled[col] = df[col].fillna(mean[col])  # Replace NaN with mean\n",
    "        df_scaled[col] = (df_scaled[col] - mean[col]) / std[col]\n",
    "    \n",
    "    return df_scaled, mean, std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### minmax_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax_scale_df(df, min_val=None, max_val=None, feature_range=(0, 1)):\n",
    "    \"\"\"\n",
    "    Min-Max scaling for numerical features in a DataFrame\n",
    "    Args:\n",
    "        df: Input pandas DataFrame\n",
    "        min_val: Precomputed min Series (if None, computes from df)\n",
    "        max_val: Precomputed max Series (if None, computes from df)\n",
    "        feature_range: Desired range of transformed data (default 0-1)\n",
    "    Returns:\n",
    "        Scaled DataFrame and computed (min_val, max_val)\n",
    "    \"\"\"\n",
    "    numerical_cols = df.select_dtypes(include=['number']).columns\n",
    "    \n",
    "    if min_val is None or max_val is None:\n",
    "        # Compute min and max while ignoring NaN values\n",
    "        min_val = df[numerical_cols].min(skipna=True)\n",
    "        max_val = df[numerical_cols].max(skipna=True)\n",
    "    \n",
    "    # Create copy to avoid SettingWithCopyWarning\n",
    "    df_scaled = df.copy()\n",
    "    \n",
    "    # Handle constant features and calculate ranges\n",
    "    ranges = max_val - min_val\n",
    "    ranges[ranges == 0] = 1.0  # avoid division by zero\n",
    "    \n",
    "    a, b = feature_range\n",
    "    \n",
    "    for col in numerical_cols:\n",
    "        # Replace NaN with midpoint of min/max\n",
    "        df_scaled[col] = df[col].fillna(min_val[col] + ranges[col]/2)\n",
    "        \n",
    "        # Scale to [0, 1] then to target range\n",
    "        df_scaled[col] = ((df_scaled[col] - min_val[col]) / ranges[col]) * (b - a) + a\n",
    "    \n",
    "    return df_scaled, min_val, max_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### simple_imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_imputer_df(df, strategy='mean', fill_value=0):\n",
    "    \"\"\"\n",
    "    Basic missing value imputation for DataFrames\n",
    "    Args:\n",
    "        df: Input pandas DataFrame\n",
    "        strategy: 'mean', 'median', 'constant', or 'mode'\n",
    "        fill_value: Value to use for 'constant' strategy\n",
    "    Returns:\n",
    "        Imputed DataFrame\n",
    "    \"\"\"\n",
    "    # Create copy to avoid SettingWithCopyWarning\n",
    "    df_imputed = df.copy()\n",
    "    \n",
    "    # Handle numerical and categorical columns differently\n",
    "    num_cols = df.select_dtypes(include=['number']).columns\n",
    "    cat_cols = df.select_dtypes(exclude=['number']).columns\n",
    "    \n",
    "    # Numerical columns\n",
    "    for col in num_cols:\n",
    "        if strategy == 'mean':\n",
    "            fill_val = df[col].mean(skipna=True)\n",
    "        elif strategy == 'median':\n",
    "            fill_val = df[col].median(skipna=True)\n",
    "        elif strategy == 'mode':\n",
    "            fill_val = df[col].mode()[0]  # Take first mode if multiple\n",
    "        elif strategy == 'constant':\n",
    "            fill_val = fill_value\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid strategy: {strategy}\")\n",
    "            \n",
    "        df_imputed[col] = df[col].fillna(fill_val)\n",
    "    \n",
    "    # Categorical columns (always use mode or constant)\n",
    "    for col in cat_cols:\n",
    "        if strategy in ['mean', 'median']:\n",
    "            # Default to mode for categorical when mean/median requested\n",
    "            fill_val = df[col].mode()[0]\n",
    "        elif strategy == 'mode':\n",
    "            fill_val = df[col].mode()[0]\n",
    "        else:  # constant\n",
    "            fill_val = fill_value\n",
    "            \n",
    "        df_imputed[col] = df[col].fillna(fill_val)\n",
    "    \n",
    "    return df_imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PolynomialRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class PolynomialRegression(nn.Module):\n",
    "    def __init__(self, degree=2):\n",
    "        super().__init__()\n",
    "        self.degree = degree\n",
    "        self.weights = nn.Parameter(torch.randn(degree + 1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Generate polynomial terms: [x^0, x^1, x^2, ..., x^degree]\n",
    "        powers = torch.stack([x**i for i in range(self.degree + 1)], dim=1)\n",
    "        return torch.matmul(powers, self.weights)\n",
    "\n",
    "# Example usage:\n",
    "def train_poly_model(X, y, degree=2, epochs=1000, lr=0.01):\n",
    "    # Convert to tensors\n",
    "    X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "    y_tensor = torch.tensor(y, dtype=torch.float32)\n",
    "    \n",
    "    # Model and optimizer\n",
    "    model = PolynomialRegression(degree=degree)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_tensor)\n",
    "        loss = criterion(outputs, y_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            print(f'Epoch {epoch}, Loss: {loss.item():.4f}')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Generate sample data\n",
    "X = torch.linspace(0, 10, 100).reshape(-1, 1)\n",
    "y = 2 * X + 3 + torch.randn(X.size()) * 2  # y = 2x + 3 + noise\n",
    "\n",
    "# Split data into train and test sets\n",
    "train_size = int(0.8 * len(X))\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# Define the linear regression model\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = nn.Linear(1, 1)  # 1 input feature, 1 output\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = LinearRegression()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test)\n",
    "    test_loss = criterion(y_pred, y_test)\n",
    "    print(f'Test Loss: {test_loss.item():.4f}')\n",
    "    \n",
    "    # Get the learned parameters\n",
    "    w = model.linear.weight.item()\n",
    "    b = model.linear.bias.item()\n",
    "    print(f'Learned parameters: w = {w:.2f}, b = {b:.2f}')\n",
    "\n",
    "# Plot the results\n",
    "plt.scatter(X_test.numpy(), y_test.numpy(), color='blue', label='Actual')\n",
    "plt.plot(X_test.numpy(), y_pred.numpy(), color='red', linewidth=2, label='Predicted')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.title('Linear Regression with PyTorch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Generate sample binary classification data\n",
    "X, y = make_classification(n_samples=100, n_features=2, n_classes=2, \n",
    "                           n_redundant=0, n_clusters_per_class=1, random_state=42)\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "# Split data into train and test sets\n",
    "train_size = int(0.8 * len(X))\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# Define the logistic regression model\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.linear(x))\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = LogisticRegression(X.shape[1])\n",
    "criterion = nn.BCELoss()  # Binary Cross Entropy Loss\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test)\n",
    "    y_pred_class = (y_pred > 0.5).float()\n",
    "    accuracy = (y_pred_class == y_test).float().mean()\n",
    "    print(f'Test Accuracy: {accuracy.item()*100:.2f}%')\n",
    "    \n",
    "    # Get the learned parameters\n",
    "    w = model.linear.weight.detach().numpy().flatten()\n",
    "    b = model.linear.bias.item()\n",
    "    print(f'Learned parameters: w = {w}, b = {b:.2f}')\n",
    "\n",
    "# Plot decision boundary (for 2D data)\n",
    "if X.shape[1] == 2:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y.numpy().flatten(), cmap='coolwarm', alpha=0.6)\n",
    "    \n",
    "    # Create mesh grid\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100), \n",
    "                         np.linspace(y_min, y_max, 100))\n",
    "    \n",
    "    # Predict probabilities\n",
    "    with torch.no_grad():\n",
    "        Z = model(torch.tensor(np.c_[xx.ravel(), yy.ravel()], dtype=torch.float32))\n",
    "        Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    # Plot decision boundary\n",
    "    plt.contour(xx, yy, Z.numpy(), levels=[0.5], colors='black')\n",
    "    plt.title('Logistic Regression Decision Boundary')\n",
    "    plt.xlabel('Feature 1')\n",
    "    plt.ylabel('Feature 2')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### xgBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost\n",
    "from sklearn.model_selection import ParameterGrid, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "# Create synthetic data for demonstration\n",
    "def create_test_data(n_samples=1000, n_features=10, random_state=42):\n",
    "    # Generate synthetic regression data\n",
    "    X, y = make_regression(n_samples=n_samples, n_features=n_features, \n",
    "                           random_state=random_state)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(n_features)])\n",
    "    y = pd.Series(y, name='target')\n",
    "    \n",
    "    # Add some missing values randomly\n",
    "    mask = np.random.random(df.shape) < 0.05  # 5% of values will be missing\n",
    "    df[mask] = np.nan\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.2, random_state=random_state)\n",
    "    X_train, X_cv, y_train, y_cv = train_test_split(X_train, y_train, test_size=0.25, random_state=random_state)\n",
    "    \n",
    "    return X_train, X_cv, X_test, y_train, y_cv, y_test\n",
    "\n",
    "def train_and_evaluate_xgboost(X_train, X_cv, X_test, y_train, y_cv, y_test):\n",
    "    # Create and configure model\n",
    "    # max_depth |\tMaximum depth of a tree\t3 - 10\n",
    "    # min_child_weight |\tMinimum sum of instance weight (hessian) in a child(Higher -> stable)\t1 - 10\n",
    "    # gamma |\tMinimum loss reduction to make a split(Higher -> stable)\t0 - 5\n",
    "    # subsample |\tRow sampling ratio for each tree\t0.5 - 1.0\n",
    "    # colsample_bytree |\tFeature sampling ratio per tree\t0.5 - 1.0\n",
    "\n",
    "    # learning_rate |\tStep size shrinkage\t0.01 - 0.3\n",
    "    # n_estimators |\tNumber of boosting rounds (trees)\t100 - 1000+\n",
    "    # early_stopping_rounds |\tStop if no improvement after N rounds (needs validation set)\t10 - 100\n",
    "\n",
    "    # lambda |\tL2 regularization on leaf weights\t0 - 10\n",
    "    # alpha |\tL1 regularization on leaf weights\t0 - 10\n",
    "    # Parameter grid\n",
    "    \n",
    "    model = xgboost.XGBRegressor(\n",
    "        learning_rate=0.03,\n",
    "        n_estimators=1000,\n",
    "        random_state=0,\n",
    "        colsample_bytree=0.9,\n",
    "        subsample=0.66\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_cv_pred = model.predict(X_cv)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    cv_rmse = np.sqrt(mean_squared_error(y_cv, y_cv_pred))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Print results\n",
    "    print('CV RMSE:', cv_rmse)\n",
    "    print('Test RMSE:', test_rmse)\n",
    "    print('Test R2:', test_r2)\n",
    "    \n",
    "    return model, y_test_pred\n",
    "\n",
    "# Run the example\n",
    "if __name__ == \"__main__\":\n",
    "    # Generate test data\n",
    "    X_train, X_cv, X_test, y_train, y_cv, y_test = create_test_data()\n",
    "    \n",
    "    print(\"Data shapes:\")\n",
    "    print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "    print(f\"X_cv: {X_cv.shape}, y_cv: {y_cv.shape}\")\n",
    "    print(f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
    "    print(\"\\nMissing values in X_train:\", X_train.isna().sum().sum())\n",
    "    \n",
    "    print(\"\\nTraining XGBoost model...\")\n",
    "    model, predictions = train_and_evaluate_xgboost(\n",
    "        X_train, X_cv, X_test, y_train, y_cv, y_test\n",
    "    )\n",
    "    \n",
    "    # Display feature importances\n",
    "    importances = pd.Series(model.feature_importances_, index=X_train.columns)\n",
    "    print(\"\\nTop 5 feature importances:\")\n",
    "    print(importances.sort_values(ascending=False).head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "explainer = shap.Explainer(model, X_train)\n",
    "shap_values_valid = explainer(X_test)\n",
    "shap.summary_plot(shap_values_valid, X_test)\n",
    "shap.plots.bar(shap_values_valid)\n",
    "\n",
    "shap_values_train = explainer(X_train)\n",
    "shap_values_valid = explainer(X_test)\n",
    "\n",
    "shap.summary_plot(shap_values_train, X_train, plot_type=\"bar\")\n",
    "shap.summary_plot(shap_values_valid, X_test, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# - x axis: false positive rate (fpr = FP / (FP + TN))\n",
    "# - y axis: true positive rate (R = TP / (TP + FN))\n",
    "# - AUC = 1 is a perfect classifier\n",
    "# - AUC > 0.5 is above chance-level predictor\n",
    "# - AUC = 0.5 is a chance-level classifier\n",
    "# - AUC < 0.5 is a bad predictor\n",
    "# - AUC = 0 classifies all points incorrectly\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "# # the roc_curve function performs the same calculation\n",
    "fpr,tpr,p_crits = roc_curve(y_test,y_pred)\n",
    "plt.plot(fpr,tpr)\n",
    "plt.xlabel('fpr')\n",
    "plt.ylabel('tpr')\n",
    "plt.title('ROC curve')\n",
    "plt.show()\n",
    "\n",
    "print(roc_auc_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### P-R cure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score # the AUC of the P-R curve\n",
    "\n",
    "p,r,p_crits = precision_recall_curve(y_test,y_pred)\n",
    "\n",
    "print(average_precision_score(y_test,y_pred))\n",
    "\n",
    "plt.plot(p,r)\n",
    "plt.xlabel('precision')\n",
    "plt.ylabel('recall')\n",
    "plt.title('P-R curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "y_pred_np = y_pred.numpy().squeeze()\n",
    "y_pred_for_matrix = np.zeros(len(y_test))\n",
    "\n",
    "# Perform thresholding\n",
    "y_pred_for_matrix[y_pred_np > 0.5] = 1\n",
    "C = confusion_matrix(y_test,y_pred_for_matrix)\n",
    "disp = ConfusionMatrixDisplay(C,display_labels=['class 0', 'class 1'])\n",
    "disp.plot()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### acc, recall, precision, F1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $\\beta < 1$, more weight to precision.\n",
    "\n",
    "If $\\beta > 1$, more weight to recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, fbeta_score\n",
    "print('accuracy',accuracy_score(y_test,y_pred))\n",
    "print('recall',recall_score(y_test,y_pred))\n",
    "print('precision',precision_score(y_test,y_pred))\n",
    "print('f1',fbeta_score(y_test,y_pred,beta=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "\n",
    "# Dummy dataset generator (for illustration)\n",
    "def generate_dummy_data(num_samples=1000, input_size=20, num_classes=2):\n",
    "    X = torch.randn(num_samples, input_size)\n",
    "    y = torch.randint(0, num_classes, (num_samples,))\n",
    "    return TensorDataset(X, y)\n",
    "\n",
    "# Example model class\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, hidden_size, input_size=20, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Train + eval function\n",
    "def train_and_eval(dataset, model, optimizer, loss_fn, batch_size):\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    # Train for a few epochs\n",
    "    model.train()\n",
    "    for epoch in range(5):  # Keep it short for tuning\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(xb)\n",
    "            loss = loss_fn(preds, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluate accuracy\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            preds = model(xb)\n",
    "            predicted = preds.argmax(dim=1)\n",
    "            correct += (predicted == yb).sum().item()\n",
    "            total += yb.size(0)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_grid_search(param_grid, train_fn, dataset, verbose=True):\n",
    "    \"\"\"\n",
    "    Manual Grid Search implementation, suitable for any training function, \n",
    "    such as PyTorch or scikit-learn models.\n",
    "\n",
    "    Args:\n",
    "        param_grid: list of dicts, where each dict is a combination of hyperparameters\n",
    "        train_fn: a function that takes one parameter set and returns (model_object, validation_score)\n",
    "        \n",
    "        verbose: whether to print progress during the search\n",
    "\n",
    "    Returns:\n",
    "        best_params: the parameter set with the highest score\n",
    "        best_model: the model corresponding to the best parameter set\n",
    "        all_results: list of all results (each with params and score)\n",
    "    \"\"\"\n",
    "    best_score = -float('inf')\n",
    "    best_model = None\n",
    "    best_params = None\n",
    "    all_results = []\n",
    "\n",
    "    for i, params in enumerate(param_grid):\n",
    "        model, score = train_fn(params, dataset)\n",
    "        all_results.append({'params': params, 'score': score})\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"[{i+1}/{len(param_grid)}] Params: {params} -> Score: {score:.4f}\")\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_model = model\n",
    "            best_params = params\n",
    "\n",
    "    return best_params, best_model, all_results\n",
    "\n",
    "def train_model(params, dataset):\n",
    "    # Example: training a PyTorch model\n",
    "    lr = params['lr']\n",
    "    batch_size = params['batch_size']\n",
    "    hidden = params['hidden']\n",
    "    \n",
    "    # Initialize your model, optimizer, and loss function here\n",
    "    model = MyModel(hidden_size=hidden)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Pseudo-code: load data, train for several epochs, evaluate on validation set\n",
    "    val_accuracy = train_and_eval(dataset, model, optimizer, loss_fn, batch_size)\n",
    "    \n",
    "    return model, val_accuracy\n",
    "\n",
    "import itertools\n",
    "\n",
    "# Construct the parameter grid (like in sklearn's GridSearch)\n",
    "param_grid = [\n",
    "    {'lr': lr, 'batch_size': bs, 'hidden': h}\n",
    "    for lr in [0.001, 0.01]\n",
    "    for bs in [32, 64]\n",
    "    for h in [128, 256]\n",
    "]\n",
    "\n",
    "dataset = generate_dummy_data()\n",
    "best_params, best_model, all_results = custom_grid_search(param_grid, train_model, dataset)\n",
    "print(\"✅ Best parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Coef for logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coef from logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Show coefficients and intercepts\n",
    "print(\"Coefficients:\", model.coef_)\n",
    "print(\"Intercepts:\", model.intercept_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
